<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>矢量化计算</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="emacsun" />
<link rel="stylesheet" type="text/css" href="../../css/worg.css" />
<a id="home" href="../../index.html"><img src="../../img/assets/home.png" ></a>
<a id="pdf"  href="./vectorize-computation.pdf"><img src="../../img/assets/pdf.png"></a>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "left",
        displayIndent: "3em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">矢量化计算</h1>
<div id="table-of-contents">
<h2>目录</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgd41669b">1. 简介</a></li>
<li><a href="#org4c5743f">2. multi-class classification</a>
<ul>
<li><a href="#org7a4bb79">2.1. 矢量化损失函数</a></li>
<li><a href="#orgdbdc741">2.2. 矢量化梯度</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-orgd41669b" class="outline-2">
<h2 id="orgd41669b"><span class="section-number-2">1</span> 简介</h2>
<div class="outline-text-2" id="text-1">
<p>

</p>

<p>
吴恩达cosera上机器学习前三次课程作业本身难度不大，很顺利完成，每次作业submit之后都是100points。值得注意的是作业特别强调计算的矢量化。这本身是一件很有意义的事情，因为以 <code>for</code> 或者 <code>while</code> 实现的矢量计算，效率远远不及以矢量本身为操作对象的计算。毕竟 <code>for</code> 或者 <code>while</code> 每次循环执行的是一个矢量元素的计算，而以矢量为操作对象的计算一次就执行了对所有元素的计算。另外，以矢量为操作对象的计算实现起来代码更简短。
</p>

<p>
这里以第三次作业为例，记录matlab实现矢量化操作的过程。
</p>
</div>
</div>

<div id="outline-container-org4c5743f" class="outline-2">
<h2 id="org4c5743f"><span class="section-number-2">2</span> multi-class classification</h2>
<div class="outline-text-2" id="text-2">
<p>

</p>

<p>
由于本文着重强调计算的矢量化，关于什么是 <code>multi-class classification</code> 在这里就不在重述，请参考 <a href="week-04-neural-networks.html">这里</a> 在作业中我们以5000个手写数字为训练样本，得到一个多类分类器。这5000个样本都是\(20\times 20\)的灰度图像，每一个像素都用一个浮点数表示其灰度。这样一个图像可以用长为400的矢量来表示。在本例中每一个样本是\(X\)的一行。
</p>
<div class="org-src-container">
<pre class="src src-matlab"><span style="color: #586e75;">% Load saved matrices from file</span>
load(<span style="color: #2aa198;">'ex3data1.mat'</span>);
<span style="color: #586e75;">% The matrices X and y will now be in your Octave environment</span>
</pre>
</div>
<p>
通过 <code>load</code> 导入训练样本\(X\)
</p>
\begin{equation}
\label{eq:1}
X =
\begin{bmatrix}
- & (x^{(1)})^{T} & - \\
- & (x^{(2)})^{T} & - \\
    &    \vdots     & - \\
- & (x^{(m)})^{T} & -
\end{bmatrix}
\end{equation}
<p>
其中\(X\)的每一行都是一个样本，存储着一个数字灰度图像的所有像素构成的矢量，这里每一行都是长为400的矢量。一共\(m\)行，代表着\(m\) 个样本，这里\(m=5000\)。另外导入的数据中还有\(y\)，包含了这\(5000\)个样本的正确映射结果。
</p>
</div>

<div id="outline-container-org7a4bb79" class="outline-3">
<h3 id="org7a4bb79"><span class="section-number-3">2.1</span> 矢量化损失函数</h3>
<div class="outline-text-3" id="text-2-1">
<p>
logistic回归的损失函数是：
</p>
\begin{equation}
\label{eq:2}
J(\theta) = \frac{1}{m} \sum_{i=1}^{m} [ -y^{(i)}\log (h_{\theta}(x^{(i)})) - (1-y^{(i)})\log(1-h_{\theta}(x^{(i)})) ]
\end{equation}

<p>
计算损失函数过程中，\(m\)是样本个数，就是说上面的函数把所有的样本都考虑在内了。为了计算求和项的每一个元素，我们需要计算\(h_{\theta}(x^{(i)})\)，其中\(h_{\theta}(x^{(i)}) = g(\theta^{T}x^{(i)})\) \(g(z) = \frac{1}{1+e^{-z}}\)。对于\(h_{\theta}(x^{(i)})\)的计算我们可以利用
</p>
\begin{equation}
\label{eq:3}
X =
\begin{bmatrix}
- & (x^{(1)})^{T} & - \\
- & (x^{(2)})^{T} & - \\
    &    \vdots     & - \\
- & (x^{(m)})^{T} & -
\end{bmatrix}
\theta =
\begin{bmatrix}
\theta_{0} \\ \theta_{1} \\ \vdots \\ \theta_{n}
\end{bmatrix}
\end{equation}
<p>
其中\(X\)的维度是\(5000\times 400\), \(\theta\)的维度是\(400\times 1\)，通过计算：
</p>
\begin{equation}
\label{eq:5}
X\theta =
\begin{bmatrix}
- & (x^{(1)})^{T}\theta & - \\
- & (x^{(2)})^{T}\theta & - \\
    &    \vdots     & - \\
- & (x^{(m)})^{T}\theta & -
\end{bmatrix}
\end{equation}
<p>
\(X\theta\)的维度是\(5000\times 1\)，然后根据~(\ref{eq:2}) 计算损失函数。
</p>

<p>
为了防止出现overfitting现象，我们通常需要对损失函数进行正则化：
</p>
\begin{equation}
\label{eq:6}
J(\theta) = \frac{1}{m} \sum_{i=1}^{m} [ -y^{(i)}\log (h_{\theta}(x^{(i)})) - (1-y^{(i)})\log(1-h_{\theta}(x^{(i)})) ] + \frac{\alpha}{2m} \sum_{j=1}^{n}\theta_{j}^{2}
\end{equation}
<p>
注意这个正则项不包括\(\theta_{0}\)，也就是说我们不对偏移项进行正则化。
</p>
</div>
</div>
<div id="outline-container-orgdbdc741" class="outline-3">
<h3 id="orgdbdc741"><span class="section-number-3">2.2</span> 矢量化梯度</h3>
<div class="outline-text-3" id="text-2-2">
<p>

</p>

<p>
未正则化的logistic regression的梯度函数是：
</p>
\begin{equation}
\label{eq:7}
\frac{\partial J}{\partial \theta_{j}} = \frac{1}{m} \sum_{i=1}^{m}( (h_{\theta}(x^{(i)}) - y^{(i)}) x_{j}^{(i)} )
\end{equation}
<p>
我们写出所有\(\frac{\partial J}{\partial \theta_{j}}\):
</p>
\begin{equation}
\label{eq:8}
\begin{bmatrix}
\frac{\partial J}{\partial \theta_{0}} \\
\frac{\partial J}{\partial \theta_{1}} \\
\frac{\partial J}{\partial \theta_{2}} \\
\vdots \\
\frac{\partial J}{\partial \theta_{n}}
\end{bmatrix}
=
\frac{1}{m}
\begin{bmatrix}
\sum_{i=1}^{m} (  (h_{\theta}(x^{(i)}) - y^{(i)}) x_{0}^{(i)} )\\
\sum_{i=1}^{m} (  (h_{\theta}(x^{(i)}) - y^{(i)}) x_{1}^{(i)} )\\
\sum_{i=1}^{m} (  (h_{\theta}(x^{(i)}) - y^{(i)}) x_{2}^{(i)} )\\
\vdots \\
\sum_{i=1}^{m} (  (h_{\theta}(x^{(i)}) - y^{(i)}) x_{n}^{(i)} )
\end{bmatrix}

\end{equation}
<p>
上式右端可以矢量化为\(\frac{1}{m} \sum_{i=1}^{m}( (h_{\theta}(x^{(i)}) -y^{(i)} )x^{（i})  = \frac{1}{m} X^{T} (h_{\theta}(x) - y) \)：
</p>

<p>
因为这个过程有两个地方体现了矢量化，所以稍微难理解一些。首先从式~(\ref{eq:8})到\(\frac{1}{m} \sum_{i=1}^{m}( (h_{\theta}(x^{(i)}) -y^{(i)} )x^{（i)})\) ， 我们可以看到\( h_{\theta}(x^{(i)}) - y^{(i)} \)是一个标量 , \(\sum_{i=1}^{m} (  (h_{\theta}(x^{(i)}) - y^{(i)}) x_{0}^{(i)} )\) 实现了 \(m\)个样本与其对应的第\(0\)个feature的点积。依次类推，我们可以得到\(\frac{1}{m} X^{T}(h_{\theta}(x)  -y ) \)
</p>

<p>
对梯度函数的正则化如下：
</p>
\begin{eqnarray*}
\frac{\partial J}{\partial \theta_{0}}&=& \frac{1}{m} \sum_{i=1}^{m}( (h_{\theta}(x^{(i)}) -y^{(i)} )x_{0}^{（i)}) \\
\frac{\partial J}{\partial \theta_{j}}&=& \frac{1}{m} \sum_{i=1}^{m}( (h_{\theta}(x^{(i)}) -y^{(i)} )x_{j}^{（i)})  + \frac{\lambda}{m}\theta_{j} \qquad \mathrm{for}\quad j\geq 1\\
\end{eqnarray*}

<p>
正则化的矢量化操作比较简单，直接加上\(\frac{\lambda}{m}\theta\)，把\(\theta\)的第一项\(\theta_{0}\)赋值为0即可。
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'zclspace';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>
</body>
</html>
